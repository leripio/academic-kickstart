<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RLeripio</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>RLeripio</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en</language><lastBuildDate>Mon, 10 Aug 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/logo.png</url>
      <title>RLeripio</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Como obter rolling windows de maneira rápida e eficiente</title>
      <link>/post/como-obter-rolling-windows-de-maneira-rapida-e-eficiente/</link>
      <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/como-obter-rolling-windows-de-maneira-rapida-e-eficiente/</guid>
      <description>

&lt;p&gt;No post &lt;a href=&#34;https://www.rleripio.com.br/post/como-generalizar-acoes-de-maneira-eficiente/&#34; target=&#34;_blank&#34;&gt;anterior&lt;/a&gt;, apresentei uma forma bastante conveniente de generalizar ações dispensando &lt;em&gt;for-loops&lt;/em&gt; tradicionais. A abordagem permite eliminar indexações trabalhosas e organizar os objetos de maneira bem prática.&lt;/p&gt;

&lt;p&gt;Outra tarefa muito presente no dia-a-dia de quem trabalha com dados é obter versões em janela móvel para alguma função. O exemplo mais simples seria a média móvel, a qual conta com implementações eficientes em diversos pacotes &amp;ndash; eu recomendo o &lt;code&gt;RcppRoll&lt;/code&gt; que, além da média móvel, também computa outras estatísticas.&lt;/p&gt;

&lt;p&gt;Entretanto, na maioria dos casos não existe uma versão &lt;em&gt;rolling&lt;/em&gt; da função desejada &amp;ndash; sobretudo para aquelas criadas por nós para atender a alguma demanda específica. É possível obter resultados &lt;em&gt;rolling&lt;/em&gt; aplicando a função desejada sobre subconjuntos dos dados e, novamente, o post &lt;a href=&#34;https://www.rleripio.com.br/post/como-generalizar-acoes-de-maneira-eficiente/&#34; target=&#34;_blank&#34;&gt;anterior&lt;/a&gt; pode ajudar nisso &amp;ndash; pense em cada subconjunto como um elemento de uma lista.&lt;/p&gt;

&lt;p&gt;Porém, existe uma forma ainda mais prática de fazer isso através da função &lt;code&gt;rollify&lt;/code&gt; do pacote &lt;code&gt;tibbletime&lt;/code&gt;. A ideia da função é criar versões &lt;em&gt;rolling&lt;/em&gt; da função desejada e a integração com &lt;code&gt;tibble&lt;/code&gt;&amp;rsquo;s torna possível retornar as saídas de maneira organizada.&lt;/p&gt;

&lt;p&gt;A sintaxe é bem simples e, para ilustrar, vamos computar uma &lt;em&gt;rolling regression&lt;/em&gt; &amp;ndash; isto é, obter o coeficiente de uma regressão em janela móvel. Isso é bem útil nas aplicações em que o coeficiente de interesse varia no tempo. No exemplo, vou retornar o coeficiente autoregressivo de um modelo &lt;strong&gt;SARIMA(1,0,0)(1,0,0)[12]&lt;/strong&gt; ajustado à série histórica do IPCA como forma de medir a inércia da inflação ao longo do tempo.&lt;/p&gt;

&lt;h3 id=&#34;passo-1-carregar-pacotes-e-importar-os-dados&#34;&gt;Passo 1: carregar pacotes e importar os dados&lt;/h3&gt;

&lt;p&gt;Para baixar a série do IPCA dos preços livres, vou utilizar o pacote &lt;code&gt;rbcb&lt;/code&gt; do Wilson Freitas. Este pacote não está mais disponível no CRAN, mas pode ser instalado a partir do &lt;a href=&#34;https://github.com/wilsonfreitas/rbcb&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt; do autor através do seguinte comando:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&#39;wilsonfreitas/rbcb&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rbcb)
library(tidyverse)
library(tibbletime)

ipca_livres &amp;lt;- rbcb::get_series(code = list(&amp;quot;ipca&amp;quot; = 11428))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;passo-2-criar-a-função-que-ajusta-o-modelo-e-retorna-o-coeficiente-ar-e-seu-erro-padrão&#34;&gt;Passo 2: criar a função que ajusta o modelo e retorna o coeficiente AR e seu erro padrão&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_ar1 &amp;lt;- function(x){
  
x_ts &amp;lt;- ts(x, frequency = 12)  
  
fit_sar1 &amp;lt;- arima(x_ts, order = c(1,0,0), seasonal = list(order = c(1,0,0)))

out &amp;lt;- list(&amp;quot;beta&amp;quot; = fit_sar1[[&amp;quot;coef&amp;quot;]][&amp;quot;ar1&amp;quot;],
            &amp;quot;se&amp;quot;   = fit_sar1[[&amp;quot;var.coef&amp;quot;]][&amp;quot;ar1&amp;quot;, &amp;quot;ar1&amp;quot;] %&amp;gt;% sqrt())

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;passo-3-criar-a-versão-rolling-da-função&#34;&gt;Passo 3: criar a versão &lt;em&gt;rolling&lt;/em&gt; da função&lt;/h3&gt;

&lt;p&gt;O argumento &lt;code&gt;window&lt;/code&gt; controla o tamanho da janela. O argumento &lt;code&gt;unlist = FALSE&lt;/code&gt; garante que os resultados ficarão no formato de lista. Isso é necessário aqui porque nosso &lt;em&gt;output&lt;/em&gt; é uma lista com dois objetos: o coeficiente e seu erro padrão.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;roll_get_ar1 &amp;lt;- tibbletime::rollify(.f = get_ar1, window = 60, unlist = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Na sequência, usamos a função criada acima para gerar um &lt;code&gt;tibble&lt;/code&gt; contendo uma coluna com o coeficiente AR(1) e outra com o erro-padrão. O &lt;code&gt;map&lt;/code&gt; é utilizado para extrair os elementos da lista.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;inercia &amp;lt;- ipca_livres %&amp;gt;%
  
  dplyr::mutate(out = roll_get_ar1(ipca)) %&amp;gt;%
  
  dplyr::filter(!is.na(out)) %&amp;gt;%
  
  dplyr::mutate(ar1 = purrr::map_dbl(.x = out, .f = function(x) x$beta),
                se  = purrr::map_dbl(.x = out, .f = function(x) x$se))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Por fim, podemos gerar um gráfico como este abaixo contendo a inércia estimada ao longo do tempo, bem como a significância do coeficiente $ \pm 1.96 \times \text{se} $. Também adicionamos uma curva suavizada (loess) para deixar a trajetória mais comportada.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/2020-08-10-como-obter-rolling-windows-de-maneira-rápida-e-eficiente_files/figure-html/plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Vale ressaltar que o modelo SARIMA é bem simples e não controla os efeitos de diversos fatores sobre a inflação &amp;ndash; atividade, câmbio, etc. Portanto, para medir adequadamente o grau de inércia precisaríamos adicionar mais estrutura à especificação.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Como generalizar ações de maneira eficiente</title>
      <link>/post/como-generalizar-acoes-de-maneira-eficiente/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/como-generalizar-acoes-de-maneira-eficiente/</guid>
      <description>

&lt;p&gt;É muito comum no dia-a-dia precisarmos generalizar alguma ação sobre diversos conjuntos de dados. Por exemplo, quando desenvolvemos uma especificação para um modelo e queremos ajustá-la sobre várias unidades diferentes. Uma maneira eficiente de pensar essa tarefa é considerar dois objetos.&lt;/p&gt;

&lt;p&gt;O primeiro é uma &lt;strong&gt;função&lt;/strong&gt; que realiza todas as ações pretendidas de forma genérica. O segundo é uma &lt;strong&gt;lista&lt;/strong&gt; cujos elementos correspondem ao conjunto de informações referente a cada unidade. No fim das contas, o objetivo será aplicar a função a cada um dos elementos da lista.&lt;/p&gt;

&lt;p&gt;Existem algumas formas de alcançar este objetivo, seja através de &lt;em&gt;loops&lt;/em&gt; convencionais ou usando as variações da família &lt;code&gt;apply&lt;/code&gt;. O conjunto de pacotes &lt;code&gt;tidyverse&lt;/code&gt; fornece uma solução bem elegante e prática através das funções &lt;code&gt;nest&lt;/code&gt; e &lt;code&gt;map&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Imagine que precisamos projetar a Produção Industrial (PIM-PF/IBGE) para todas as UF&amp;rsquo;s disponíveis na pesquisa do IBGE. Como seria?&lt;/p&gt;

&lt;h2 id=&#34;passo-1-carregar-pacotes-e-importar-os-dados&#34;&gt;Passo 1: carregar pacotes e importar os dados&lt;/h2&gt;

&lt;p&gt;Para importar os dados, vamos acessar a API do IBGE através do pacote &lt;code&gt;sidrar&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(sidrar)
library(tidyverse)
library(fable)
library(tsibble)

dados_pim &amp;lt;- &amp;quot;/t/3653/n3/all/v/3135/p/all/c544/129314/d/v3135%201&amp;quot;

pim_ibge &amp;lt;- sidrar::get_sidra(api = dados_pim)

pim_ibge &amp;lt;- pim_ibge %&amp;gt;%
  
  dplyr::select(date = `Mês (Código)`,
                uf   = `Unidade da Federação`,
                valor = Valor) %&amp;gt;%
  
  dplyr::mutate(date = lubridate::ymd(paste0(date, &amp;quot;01&amp;quot;)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;passo-2-colocar-os-dados-no-formato-nest&#34;&gt;Passo 2: colocar os dados no formato nest&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pim_ibge_nest &amp;lt;- pim_ibge %&amp;gt;%
  
  dplyr::group_by(uf) %&amp;gt;%
  
  tidyr::nest()

pim_ibge_nest
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 2
## # Groups:   uf [14]
##    uf                data              
##    &amp;lt;chr&amp;gt;             &amp;lt;list&amp;gt;            
##  1 Amazonas          &amp;lt;tibble [221 × 2]&amp;gt;
##  2 Pará              &amp;lt;tibble [221 × 2]&amp;gt;
##  3 Ceará             &amp;lt;tibble [221 × 2]&amp;gt;
##  4 Pernambuco        &amp;lt;tibble [221 × 2]&amp;gt;
##  5 Bahia             &amp;lt;tibble [221 × 2]&amp;gt;
##  6 Minas Gerais      &amp;lt;tibble [221 × 2]&amp;gt;
##  7 Espírito Santo    &amp;lt;tibble [221 × 2]&amp;gt;
##  8 Rio de Janeiro    &amp;lt;tibble [221 × 2]&amp;gt;
##  9 São Paulo         &amp;lt;tibble [221 × 2]&amp;gt;
## 10 Paraná            &amp;lt;tibble [221 × 2]&amp;gt;
## 11 Santa Catarina    &amp;lt;tibble [221 × 2]&amp;gt;
## 12 Rio Grande do Sul &amp;lt;tibble [221 × 2]&amp;gt;
## 13 Mato Grosso       &amp;lt;tibble [221 × 2]&amp;gt;
## 14 Goiás             &amp;lt;tibble [221 × 2]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Repare no &lt;code&gt;tibble&lt;/code&gt; criado pela função &lt;code&gt;nest&lt;/code&gt;. Diferente das estruturas convencionais, ele permite armazenar objetos dentro das células &amp;ndash; aqui serão os &lt;code&gt;tibble&lt;/code&gt;&amp;rsquo;s contendo os dados para cada UF. Na prática, isso funciona como uma &lt;em&gt;lista&lt;/em&gt; sobre a qual podemos usar o &lt;code&gt;map&lt;/code&gt; para aplicar a nossa função.&lt;/p&gt;

&lt;p&gt;Vale ressaltar que seria equivalente utilizar uma lista. Para isso, poderíamos recorrer à função &lt;code&gt;dlply&lt;/code&gt; do pacote &lt;code&gt;plyr&lt;/code&gt; conforme apresentado a seguir. A vantagem do formato &lt;code&gt;nest&lt;/code&gt; é que você pode ir adicionando novas colunas com outras transformações aos dados sem a necessidade de criar novos objetos.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)

pim_ibge_list &amp;lt;- pim_ibge %&amp;gt;%
  
  plyr::dlply(.variables = &amp;quot;uf&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;passo-3-criar-a-função&#34;&gt;Passo 3: criar a função&lt;/h2&gt;

&lt;p&gt;Nossa função não precisa ser tão geral neste caso, dado que os nomes das colunas são iguais para todas as UF&amp;rsquo;s &amp;ndash; &lt;code&gt;date&lt;/code&gt; e &lt;code&gt;valor&lt;/code&gt; &amp;ndash; e o modelo também será o mesmo. Basicamente, a ação aqui é pegar o argumento &lt;code&gt;x&lt;/code&gt; que será um &lt;code&gt;tibble&lt;/code&gt; e retornar as projeções de 1 a 6 períodos à frente utilizando um &lt;code&gt;ARIMA&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fc_arima &amp;lt;- function(x){
    
    x %&amp;gt;%
      
      dplyr::mutate(date = tsibble::yearmonth(date)) %&amp;gt;%
      
      as_tsibble() %&amp;gt;%
      
      model(modelo = ARIMA(valor)) %&amp;gt;%
      
      forecast(h = 6)
    
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;passo-4-estimar-os-modelos&#34;&gt;Passo 4: estimar os modelos&lt;/h2&gt;

&lt;p&gt;De posse dos dados devidamente segmentados e da função, podemos usar a função &lt;code&gt;map&lt;/code&gt; para finalizar o trabalho.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pim_ibge_modelo &amp;lt;- pim_ibge_nest %&amp;gt;% 
  
  dplyr::mutate(modelos = purrr::map(.x = data, .f = fc_arima))

pim_ibge_modelo
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 3
## # Groups:   uf [14]
##    uf                data               modelos        
##    &amp;lt;chr&amp;gt;             &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;         
##  1 Amazonas          &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  2 Pará              &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  3 Ceará             &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  4 Pernambuco        &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  5 Bahia             &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  6 Minas Gerais      &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  7 Espírito Santo    &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  8 Rio de Janeiro    &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
##  9 São Paulo         &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
## 10 Paraná            &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
## 11 Santa Catarina    &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
## 12 Rio Grande do Sul &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
## 13 Mato Grosso       &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
## 14 Goiás             &amp;lt;tibble [221 × 2]&amp;gt; &amp;lt;fable [6 × 4]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cada célula da coluna &lt;code&gt;modelos&lt;/code&gt; contém o resultado da função, isto é, as informações sobre a distribuição das projeções para cada UF. Isto permite acessar tais informações como se fossem uma lista e, por exemplo, plotar gráficos como estes abaixo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/2020-07-29-como-generalizar-acoes-de-maneira-eficiente_files/figure-html/step7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Para funções com mais de um argumento, a função &lt;code&gt;map&lt;/code&gt; dispõe de variantes: &lt;code&gt;map2&lt;/code&gt; para dois argumentos e &lt;code&gt;pmap&lt;/code&gt; para múltiplos argumentos. Também seria factível usar um modelo para cada UF. O ponto aqui era mostrar que a abordagem &lt;strong&gt;função + lista&lt;/strong&gt; elimina em grande medida repetições desnecessárias de código, além da facilidade em escalar o trabalho apenas adicionando novos elementos à lista.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Como fazer um tracking eficiente das suas projeções</title>
      <link>/post/como-fazer-um-tracking-eficiente-das-suas-projecoes/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/como-fazer-um-tracking-eficiente-das-suas-projecoes/</guid>
      <description>

&lt;p&gt;Quem realiza projeções deve manter seus resultados armazenados, de modo que seja possível recuperá-los a qualquer momento. Isso permite, por exemplo, acompanhar o desempenho do modelo ao longo do tempo.&lt;/p&gt;

&lt;p&gt;A tarefa pode ser feita em dois passos. Primeiro, criar um &lt;code&gt;tibble&lt;/code&gt; com três colunas: a data &lt;strong&gt;na&lt;/strong&gt; qual as projeções foram geradas; a data &lt;strong&gt;para a qual&lt;/strong&gt; as projeções foram feitas; e, por fim, os valores (ou distribuição) projetados. É possível também adicionar informações extras, como a especificação do modelo utilizado &amp;ndash; caso este seja atualizado regularmente.&lt;/p&gt;

&lt;p&gt;O segundo passo é armazenar fisicamente a informação para que seja possível acessá-la mais tarde. Aqui, eu prefiro utilizar o objeto &lt;code&gt;RDS&lt;/code&gt; &amp;ndash; que é, basicamente, a estrutura para armazenagem de objetos do R. Uma boa ideia neste caso é exportar um arquivo &lt;code&gt;RDS&lt;/code&gt; contendo o &lt;code&gt;tibble&lt;/code&gt; a cada nova rodada de projeções e mantê-los em uma pasta.&lt;/p&gt;

&lt;p&gt;Vamos a um exemplo prático de como fazer isso. Para utilizar um contexto atual, vamos assumir que nosso objetivo seja projetar todos os dias o número de novos casos de Covid-19 no Brasil para os próximos 7 dias a partir de um modelo univariado bem simples &amp;ndash; um &lt;code&gt;ETS&lt;/code&gt; automático do pacote &lt;code&gt;fable&lt;/code&gt; (a versão &lt;code&gt;tidy&lt;/code&gt; do pacote &lt;code&gt;forecast&lt;/code&gt;). Os dados são importados do repositório público do Wesley Cota (&lt;a href=&#34;https://github.com/wcota/covid19br/&#34; target=&#34;_blank&#34;&gt;https://github.com/wcota/covid19br/&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;passo-1-carregar-pacotes-e-obter-os-dados&#34;&gt;Passo 1: carregar pacotes e obter os dados&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(lubridate)
library(fable)
library(tsibble)

dados_url &amp;lt;- &amp;quot;https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-states.csv&amp;quot;

dadosBR &amp;lt;- readr::read_csv(dados_url) %&amp;gt;%
  
  dplyr::filter(country == &amp;quot;Brazil&amp;quot;, state == &amp;quot;TOTAL&amp;quot;,
                date &amp;gt;= max(date) %m-% days(60)) %&amp;gt;%
  
  dplyr::select(date, newCases)

tail(dadosBR, 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   date       newCases
##   &amp;lt;date&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 2020-07-21    46927
## 2 2020-07-22    62943
## 3 2020-07-23    56111
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;passo-2-ajustar-o-modelo-ets-realizar-as-projeções-e-salvar-objeto-rds&#34;&gt;Passo 2: ajustar o modelo ETS, realizar as projeções e salvar objeto RDS&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;  proj &amp;lt;- dadosBR %&amp;gt;%
  
  as_tsibble() %&amp;gt;%
  
  model(ets = ETS(newCases)) %&amp;gt;%
  
  forecast(h = &amp;quot;7 days&amp;quot;) %&amp;gt;%
  
  dplyr::mutate(dateFrom = max(dadosBR$date))

tail(proj, 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A fable: 3 x 5 [1D]
## # Key:     .model [1]
##   .model date       newCases .distribution     dateFrom  
##   &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dist&amp;gt;            &amp;lt;date&amp;gt;    
## 1 ets    2020-07-28   46116. N(46116, 7.8e+07) 2020-07-23
## 2 ets    2020-07-29   47461. N(47461, 8.2e+07) 2020-07-23
## 3 ets    2020-07-30   47584. N(47584, 8.3e+07) 2020-07-23
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Em seguida, basta salvar o objeto. Uma boa ideia é incluir alguma referência no nome do arquivo: a data em que foram geradas as projeções ou a data da última observação disponível, por exemplo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;saveRDS(proj, paste0(&amp;quot;tracking/forecast_&amp;quot;, unique(proj$dateFrom), &amp;quot;.rds&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para termos uma noção do que seria o resultado ao longo de um período maior, reproduzi a ação anterior por um período de 30 dias. Assim, existem na pasta 30 arquivos &lt;code&gt;.rds&lt;/code&gt; correspondendo à trajetória de projeção gerada em cada um dos 30 dias. Esses arquivos podem ser importados de uma só vez &amp;ndash; utilizando como identificador um padrão do nome ou simplesmente a extensão &amp;ndash; e empilhados para produzir as análises.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;proj_labs &amp;lt;- list.files(&amp;quot;tracking/&amp;quot;)[str_detect(list.files(&amp;quot;tracking/&amp;quot;), &amp;quot;.rds&amp;quot;)]

proj_files &amp;lt;- purrr::map_dfr(.x = proj_labs, 
                             .f = function(x) readRDS(paste0(&amp;quot;tracking/&amp;quot;, x)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para finalizar, devemos adicionar os dados que foram realizados. Isto pode ser feito dando um &lt;code&gt;join&lt;/code&gt; com o nosso objeto &lt;code&gt;dadosBR&lt;/code&gt;, utilizando a coluna de data como identificador. Para que o &lt;code&gt;tibble&lt;/code&gt; fique mais claro, vamos renomear a coluna.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;proj_tracking &amp;lt;- dplyr::left_join(
  
  proj_files %&amp;gt;% 
    
    as_tibble() %&amp;gt;%
    
    dplyr::rename(&amp;quot;previsto&amp;quot; = &amp;quot;newCases&amp;quot;),
  
  dadosBR %&amp;gt;% dplyr::rename(&amp;quot;realizado&amp;quot; = &amp;quot;newCases&amp;quot;)
  
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Podemos utilizar &lt;code&gt;proj_tracking&lt;/code&gt; de diversas formas para acompanhar o desempenho do nosso modelo. O gráfico abaixo, por exemplo, traz a evolução das projeções um passo à frente. Apesar de o modelo não ser tão aderente à magnitude, ele é capaz de capturar a sazonalidade da série. Vale lembrar que o modelo utilizado é bem simples e serve apenas para ilustração.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/post/2020-07-17-como-fazer-um-tracking-eficiente-das-suas-projeções_files/figure-html/plot-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Por fim, também podemos utilizar os dados gerados anteriormente para computar métricas de acurácia para cada horizonte de previsão. Para isso, vamos utilizar a função &lt;code&gt;mape&lt;/code&gt; do pacote &lt;code&gt;yardstick&lt;/code&gt; para obter o erro absoluto percentual médio (MAPE). O pacote conta com diversas outras métricas conhecidas: &lt;code&gt;rmse&lt;/code&gt;, &lt;code&gt;mae&lt;/code&gt;, &lt;code&gt;mase&lt;/code&gt;, etc.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(yardstick)

proj_acc &amp;lt;- proj_tracking %&amp;gt;%
  
  dplyr::group_by(dateFrom) %&amp;gt;%
  
  dplyr::mutate(step_ahead = 1:n()) %&amp;gt;%
  
  dplyr::group_by(step_ahead) %&amp;gt;%
  
  yardstick::mape(truth = realizado, estimate = previsto, na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post/2020-07-17-como-fazer-um-tracking-eficiente-das-suas-projeções_files/figure-html/acc_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Usando tidyr para criar dummies e lags</title>
      <link>/post/usando-tidyr-pivot-para-criar-dummies-e-lags/</link>
      <pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/usando-tidyr-pivot-para-criar-dummies-e-lags/</guid>
      <description>&lt;p&gt;Imagine que você tenha uma base de dados com dezenas (ou centenas) de variáveis e quer criar os &lt;em&gt;lags&lt;/em&gt; de 1 a 5 para cada uma destas variáveis. Além disso, precisa adicionar &lt;em&gt;dummies&lt;/em&gt; mensais para controlar algum fator sazonal. Esta tarefa faz parte do dia-a-dia de quem trabalha com modelos econométricos/machine learning e ter uma forma prática ajuda bastante.&lt;/p&gt;

&lt;p&gt;Existem algumas formas de resolver esse problema. Uma bem simples e prática envolve o &lt;code&gt;tidyr&lt;/code&gt;, pacote do &lt;code&gt;tidyverse&lt;/code&gt; dedicado à manipulação de &lt;em&gt;frames&lt;/em&gt;. Suas principais funções são &lt;code&gt;pivot_longer&lt;/code&gt; e &lt;code&gt;pivot_wider&lt;/code&gt;, usadas para posicionar os dados, respectivamente, em formato &lt;em&gt;long&lt;/em&gt; e &lt;em&gt;wide&lt;/em&gt;. Fazendo uso correto destas funções e de seus argumentos, é possível resolver o problema de forma muito simples. Então vamos lá!&lt;/p&gt;

&lt;p&gt;Para começar, vou criar uma &lt;em&gt;frame&lt;/em&gt; artificial contendo uma coluna com datas mensais e três colunas representando diferentes variáveis &amp;ndash; var1, var2 e var3. Lembrando que a abordagem é geral o suficiente para acomodar qualquer número de variáveis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(lubridate)

set.seed(123)

df &amp;lt;- tibble(data = seq(ymd(&amp;quot;2019-01-01&amp;quot;), ymd(&amp;quot;2020-07-01&amp;quot;), by = &amp;quot;month&amp;quot;),
             var1 = rnorm(19),
             var2 = rnorm(19),
             var3 = rnorm(19))

tail(df, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 4
##   data         var1    var2    var3
##   &amp;lt;date&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 2020-03-01 -0.556  0.878  -0.0429
## 2 2020-04-01  1.79   0.822   1.37  
## 3 2020-05-01  0.498  0.689  -0.226 
## 4 2020-06-01 -1.97   0.554   1.52  
## 5 2020-07-01  0.701 -0.0619 -1.55
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;De início, vamos criar as &lt;em&gt;dummies&lt;/em&gt; sazonais. O primeiro passo é criar uma coluna com os meses da coluna de datas. A função &lt;code&gt;month&lt;/code&gt; do pacote &lt;code&gt;lubridate&lt;/code&gt; fornece uma forma conveniente para isso. Em seguida, criamos uma coluna com valores iguais a 1 &amp;ndash; isso ficará mais claro adiante e os nomes das colunas não importam. Por fim, recorremos à função &lt;code&gt;pivot_wider&lt;/code&gt;. Transpondo a coluna dos meses e preenchendo com os 1&amp;rsquo;s, obteríamos um &lt;em&gt;frame&lt;/em&gt; no qual cada mês é uma coluna onde o valor é igual a 1 para o mês correspondente na coluna data e &lt;code&gt;NA&lt;/code&gt; nos demais. Como nosso objetivo é ter 0&amp;rsquo;s no lugar desses &lt;code&gt;NA&lt;/code&gt;, usamos o argumento &lt;code&gt;values_fill&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df_seasonal &amp;lt;- df %&amp;gt;%
  
  mutate(meses = month(data, label = T, abbr = T),
         um = 1) %&amp;gt;%
  
  pivot_wider(names_from = meses, values_from = um, values_fill = list(um = 0))

tail(df_seasonal, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 16
##   data         var1    var2    var3   jan   fev   mar   abr   mai   jun   jul
##   &amp;lt;date&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 2020-03-01 -0.556  0.878  -0.0429     0     0     1     0     0     0     0
## 2 2020-04-01  1.79   0.822   1.37       0     0     0     1     0     0     0
## 3 2020-05-01  0.498  0.689  -0.226      0     0     0     0     1     0     0
## 4 2020-06-01 -1.97   0.554   1.52       0     0     0     0     0     1     0
## 5 2020-07-01  0.701 -0.0619 -1.55       0     0     0     0     0     0     1
## # … with 5 more variables: ago &amp;lt;dbl&amp;gt;, set &amp;lt;dbl&amp;gt;, out &amp;lt;dbl&amp;gt;, nov &amp;lt;dbl&amp;gt;,
## #   dez &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora vamos criar os &lt;em&gt;lags&lt;/em&gt; das variáveis. Aqui a gente vai usar tanto a &lt;code&gt;pivot_longer&lt;/code&gt; como &lt;code&gt;pivot_wider&lt;/code&gt;. O primeiro passo é deixar o &lt;em&gt;frame&lt;/em&gt; no formato &lt;em&gt;long&lt;/em&gt;, isto é, as variáveis serão empilhadas em uma única coluna que eu chamarei de &amp;ldquo;var&amp;rdquo;. Os valores ficarão na coluna &amp;ldquo;l0&amp;rdquo; que denota o &lt;em&gt;lag&lt;/em&gt; 0.&lt;/p&gt;

&lt;p&gt;Na sequência, vamos criar colunas com os &lt;em&gt;lags&lt;/em&gt; desejados: 1 a 5. Essas colunas também precisarão ser colocadas no formato &lt;em&gt;long&lt;/em&gt;. Finalmente, vamos expandir o &lt;em&gt;frame&lt;/em&gt; (formato &lt;em&gt;wider&lt;/em&gt;) reunindo as duas colunas: &amp;ldquo;var&amp;rdquo; e &amp;ldquo;lags&amp;rdquo;. Isto produzirá o resultado desejado. O &lt;code&gt;group_by&lt;/code&gt; e &lt;code&gt;arrange&lt;/code&gt; são utilizados para garantir a ordem temporal dos dados.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df_lags &amp;lt;- df %&amp;gt;%
  
  pivot_longer(-&amp;quot;data&amp;quot;, names_to = &amp;quot;var&amp;quot;, values_to = &amp;quot;l0&amp;quot;) %&amp;gt;%
  
  group_by(var) %&amp;gt;%
  
  arrange(data) %&amp;gt;%
  
  mutate(l1 = lag(l0, 1),
         l2 = lag(l0, 2),
         l3 = lag(l0, 3),
         l4 = lag(l0, 4),
         l5 = lag(l0, 5)) %&amp;gt;%
  
  pivot_longer(-c(data, var), names_to = &amp;quot;lag&amp;quot;, values_to = &amp;quot;valor&amp;quot;) %&amp;gt;%
  
  pivot_wider(names_from = c(&amp;quot;var&amp;quot;, &amp;quot;lag&amp;quot;), values_from = &amp;quot;valor&amp;quot;)

tail(df_lags, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 19
##   data       var1_l0 var1_l1 var1_l2 var1_l3 var1_l4 var1_l5 var2_l0 var2_l1
##   &amp;lt;date&amp;gt;       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 2020-03-01  -0.556   0.111   0.401   0.360   1.22   -0.446  0.878    0.895
## 2 2020-04-01   1.79   -0.556   0.111   0.401   0.360   1.22   0.822    0.878
## 3 2020-05-01   0.498   1.79   -0.556   0.111   0.401   0.360  0.689    0.822
## 4 2020-06-01  -1.97    0.498   1.79   -0.556   0.111   0.401  0.554    0.689
## 5 2020-07-01   0.701  -1.97    0.498   1.79   -0.556   0.111 -0.0619   0.554
## # … with 10 more variables: var2_l2 &amp;lt;dbl&amp;gt;, var2_l3 &amp;lt;dbl&amp;gt;, var2_l4 &amp;lt;dbl&amp;gt;,
## #   var2_l5 &amp;lt;dbl&amp;gt;, var3_l0 &amp;lt;dbl&amp;gt;, var3_l1 &amp;lt;dbl&amp;gt;, var3_l2 &amp;lt;dbl&amp;gt;, var3_l3 &amp;lt;dbl&amp;gt;,
## #   var3_l4 &amp;lt;dbl&amp;gt;, var3_l5 &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A grande vantagem desta abordagem é não precisar escrever o nome das variáveis para criar os &lt;em&gt;lags&lt;/em&gt; &amp;ndash; lembrem-se de que elas podem ser dezenas ou centenas. Adicionalmente, não precisamos criar funções auxiliares ou recorrer à geração dinâmica de variáveis &amp;ndash; o que no contexto do &lt;code&gt;tidyverse&lt;/code&gt; envolve algum tipo de &lt;em&gt;Non-Standard Evaluation&lt;/em&gt; &amp;ndash; nem sempre tão simples para quem tá começando.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Utilizando redes neurais para combinar modelos</title>
      <link>/post/utilizando-redes-neurais-para-combinar-modelos/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/utilizando-redes-neurais-para-combinar-modelos/</guid>
      <description>&lt;p&gt;No post &lt;a href=&#34;http://rleripio.com.br/post/combinando-modelos-de-previsao/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Combinando modelos de previsão&amp;rdquo;&lt;/a&gt;, apresentei duas formas simples de combinar modelos de previsão. A primeira delas envolvia obter uma combinação linear das previsões individuais de cada modelo, através de um método de otimização (OLS, por exemplo, ou equivalente). O segundo método utilizava a mediana das projeções dos modelos individuais. Embora operacionalmente mais simples, esta última abordagem performou melhor que a anterior &amp;ndash; um resultado nada surpreendente, pois existe literatura mostrando que é mesmo difícil obter resultados melhores que a combinação por mediana daqueles modelos empregados.&lt;/p&gt;

&lt;p&gt;Combinação de modelos tornou-se um novo paradigma em previsões. Conforme citado naquele post:&lt;/p&gt;

&lt;p&gt;[&amp;hellip;] a estratégia parece ter definido um novo padrão no campo de previsões uma vez que &lt;strong&gt;12 dos 17 modelos mais acurados na competição M4 foram combinações&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Na ocasião, mencionei também que haviam formas mais sofisticadas de combinar modelos. Segue a passagem:&lt;/p&gt;

&lt;p&gt;[&amp;hellip;] Métodos mais sofisticados permitem, por exemplo, mudanças no valor dos parâmetros ao longo do tempo e até mesmo a utilização de &lt;strong&gt;algoritmos de Machine Learning&lt;/strong&gt; para aprender o valor destes parâmetros.&lt;/p&gt;

&lt;p&gt;O post de hoje busca justamente isso: utilizar uma &lt;strong&gt;rede neural&lt;/strong&gt; para combinar modelos. Para isto, vamos utilizar aqueles mesmos quatro modelos: &lt;strong&gt;CES&lt;/strong&gt;, &lt;strong&gt;ETS&lt;/strong&gt;, &lt;strong&gt;DOTM&lt;/strong&gt; e &lt;strong&gt;ARIMA&lt;/strong&gt;. Entretanto, optei desta vez por utilizar a série temporal do índice VIX, divulgado pelo CBOE (Chicago Board Options Exchange). Para os menos familiarizados, o índice VIX busca medir a volatilidade esperada na bolsa americana. A escolha da série, dentre outros motivos, justifica-se por seu tamanho: 355 observações mensais. Sabe-se que redes neurais são &lt;em&gt;data hungry&lt;/em&gt;, logo séries curtas podem não apresentar bons resultados. A principal vantagem de utilizar uma rede neural para aprender qual a melhor forma de combinar os modelos é sua flexibilidade, isto é, os pesos atribuídos a cada modelo poderá ser uma função não-linear, potencialmente complexa.&lt;/p&gt;

&lt;p&gt;Entendido o objetivo, vamos iniciar o exercício. De modo a poder contar com um número maior de observações, criei a amostra da seguinte forma:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Computei as projeções um-passo-à-frente de cada modelo através de validação-cruzada. Utilizando uma janela móvel de 100 observações para as projeções, obtive um total próximo a 250 previsões (fora da amostra).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Desta amostra, separei cerca de 70% para treino e 30% para teste. A amostra de treino foi utilizada para calcular os pesos por OLS e também para treinar a Rede Neural. A combinação por mediana foi calculada diretamente sobre a amostra de teste, pois não envolve nenhuma estimativa de parâmetros.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Por fim, foram computados o Mean Squared Error (MSE) de todos os métodos.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Os resultados seguem abaixo. Diferente dos resultados do post anterior, a mediana não foi capaz de superar todos os modelos individuais. Isto, provavelmente, é consequência de existirem dois modelos cujas performances se distanciam bastante dos demais &amp;ndash; ARIMA e CES.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;modelo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;MSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;dotm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.041486&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ets&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.090884&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;mediana&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.110720&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;arima&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.358005&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ces&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.519399&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A combinação, por sua vez, também não foi capaz de entregar resultados superiores. Em outras palavras, na presença de modelos ruins, métodos mais convencionais de combinação tendem a não performar muito bem.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;modelo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;MSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;dotm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.041486&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ets&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.090884&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;mediana&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.110720&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;combinação&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.175815&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;arima&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.358005&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ces&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.519399&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;E o que dizer da combinação através da rede neural? Antes de apresentar o resultado, vou descrever um pouco melhor a especificação utilizada. A rede neural usada aqui é do tipo &lt;em&gt;feed forward&lt;/em&gt;, com quatro &lt;em&gt;layers&lt;/em&gt; contendo 16 &lt;em&gt;units&lt;/em&gt; cada. As funções de ativação dos três primeiros &lt;em&gt;layers&lt;/em&gt; é &lt;em&gt;relu&lt;/em&gt;, enquanto a do último é &lt;em&gt;linear&lt;/em&gt;. No total, foram treinados 641 parâmetros. &lt;strong&gt;A combinação através da rede neural retornou um MSE de 4.49&lt;/strong&gt;, cerca de metade daquele reportado pelo melhor modelo individual &amp;ndash; DOTM. O resultado é muito bom, mas valem alguns avisos. O primeiro é usual, mas nunca demais repetir: não necessariamente este aumento de performance vai acontecer para qualquer série. O segundo é mais específico: o treinamento de redes neurais envolve alguns processos estocásticos, de modo que pode ocorrer instabilidade nos parâmetros estimados e, portanto, sobre a própria acurácia do modelo. Uma solução seria treinar a rede neural um grande número de vezes e reportar a acurácia mediana. Obviamente isto envolve um grande custo operacional.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;2019-08-09-utilizando-redes-neurais-para-combinar-modelos_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;864&#34; /&gt;&lt;/p&gt;

&lt;p&gt;O que chama mais atenção nos resultados é a capacidade da rede neural em evitar as projeções mais acentuadas para baixo. Note que em diversos casos isto faz com que a projeção se distancie muito do valor realizado. A princípio, tudo indica que a rede neural foi capaz de aprender a não dar muito peso para o modelo (ou os modelos) com essa tendência de subestimar demais a série em certos momentos. Adicionalmente, a combinação através da rede neural também não superestima demais alguns valores. Em suma, parece que em situações mais usuais ambos os métodos são razoáveis. Porém, na presença de desvios mais acentuados, a rede neural é capaz de entregar resultados mais próximos do observado. Essa é uma virtude importante, sobretudo por se tratar de uma série que mede volatilidade e, portanto, apresenta regiões mais &amp;ldquo;nervosas&amp;rdquo;. Neste caso, é importante que o modelo não perca a mão quando esse momento aparecer.&lt;/p&gt;

&lt;p&gt;Por fim, uma possível estratégia para melhorar o método de combinação linear ou de mediana seria remover aquele modelo com desempenho muito ruim &amp;ndash; no nosso caso, o CES. Uma generalização desse processo seria estimar diversos (ou todos) subconjuntos de modelos, calcular a acurácia da combinação de cada subconjunto e selecionar aquele com melhor poder preditivo. Talvez possamos abordar isso numa próxima oportunidade.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Os códigos dos exercícios&lt;/strong&gt; encontram-se disponíveis no &lt;a href=&#34;https://github.com/leripio/blog&#34; target=&#34;_blank&#34;&gt;repositório do blog no github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal:&lt;/strong&gt; Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tales from tails: analisando o risco em previsões</title>
      <link>/post/tales-from-tails-analisando-o-risco-em-previsoes/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/tales-from-tails-analisando-o-risco-em-previsoes/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://rleripio.com.br/post/combinando-modelos-de-previsao/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;No post anterior&lt;/em&gt;&lt;/a&gt;, tratei de estratégias para combinar modelos de previsão a fim de obter melhores resultados. Melhor resultado, naquele contexto, significava apresentar menor &lt;strong&gt;Root mean square forecast error (RMSFE)&lt;/strong&gt;.É muito comum &amp;ndash; tanto na literatura como na prática &amp;ndash; utilizar esta medida ou outras semelhantes que envolvam médias dos desvios quadráticos ou absolutos dos erros, por exemplo MSE, MSPE, MASE, MAPE, etc. &lt;strong&gt;Sabe-se, contudo, que médias são muito sensíveis a valores extremos.&lt;/strong&gt; Portanto, um único valor extremo no conjunto de erros de previsão é capaz de elevar de maneira significativa aquelas estatísticas. Dito de outra forma, um modelo relativamente bom pode ser descartado porque apresentou uma única previsão ruim. Por esta razão, ganhou popularidade medidas que substituem a média pela mediana naquelas estatísticas anteriores. Os interessados em entender melhor as características destas medidas podem recorrer ao artigo de Hyndman e Koehler (2006): &lt;a href=&#34;https://robjhyndman.com/papers/mase.pdf&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;&amp;ldquo;Another look at measures of forecast accuracy&amp;rdquo;&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Neste ponto, eu gostaria de chamar atenção para uma coisa muito importante: &lt;strong&gt;a estatística de acurácia utilizada para ranquear modelos é uma função-perda e, como tal, reflete o objetivo que se pretende alcançar.&lt;/strong&gt;Se o objetivo é reter o modelo que, em geral, não apresenta previsões muito distantes das realizações, as medidas consideradas até agora são razoáveis. Por outro lado, imagine que a previsão seja para o estoque de uma empresa ou para uma variável que define uma posição de investimento. &lt;strong&gt;Nestes casos, o risco da previsão importa.&lt;/strong&gt;Em outras palavras, pode não fazer muito sentido escolher um modelo que, apesar de ter bom desempenho na média/mediana, apresenta maiores chances de valores extremos. No caso da empresa, tanto o excesso quanto a falta de estoque em níveis elevados pode comprometer as operações; igualmente catastrófico pode ser a realização muito abaixo/acima do previsto para uma variável-chave para o investidor.
Para usar um exemplo real, vamos considerar a mesma variável utilizada no post anterior: o núcleo do IPCA EX-3. A amostra vai de julho de 2006 a maio de 2019 e contém 155 observações. Os modelos utilizados foram ARIMA, ETS, CES e DOTM &amp;ndash; todos vistos naquela ocasião &amp;ndash; e os erros de previsão um passo à frente computados a partir de validação-cruzada com uma janela móvel de 60 observações &amp;ndash; o que totalizou cerca de 95 pontos de erro para cada modelo. As densidades dos erros de previsão para cada modelo são apresentadas abaixo:
&lt;img src=&#34;2019-07-29-tales-from-tails-analisando-o-risco-em-previsões_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;
De modo geral, todas as distribuições apresentam maior ocorrência em torno do zero, o que sugere que medidas que computam a tendência central devem ter desempenho mais ou menos parecido. Porém, cabe notar que a cauda das distribuições têm formatos bem diferentes: os erros do modelo ETS têm a cauda da direita maior que a do modelo DOTM e CES, por exemplo. É justamente neste aspecto que reside a ideia de risco: &lt;strong&gt;a probabilidade de eventos extremos é maior ou menor de acordo com a área destas caudas&lt;/strong&gt;. Para traduzir isso de forma mais objetiva, o gráfico abaixo traz três medidas: duas de tendência central &amp;ndash; Root mean square forecast error (RMSFE) e Root median square forecast error (RMedSFE) &amp;ndash; e uma de risco: os limites da área com probabilidade de 10% à direita e à esquerda &amp;ndash; esta última em valor absoluto para ficar mais fácil de visualizar com as demais.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;2019-07-29-tales-from-tails-analisando-o-risco-em-previsões_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;1152&#34; /&gt;&lt;/p&gt;

&lt;p&gt;O primeiro ponto a notar é que existe diferença na classificação quando consideramos a média ou a mediana. Pelo RMSFE, a escolha seria pelo DOTM, ao passo que pelo RMedSFE o modelo escolhido seria o CES. Por outro lado, se quiséssemos reduzir as chances de valores extremos &amp;ndash; tanto para cima quanto para baixo &amp;ndash; o DOTM seria a escolha inequívoca. Fica claro, portanto, a relevância de utilizar medidas aderentes aos objetivos da previsão. Adicionalmente, é sempre uma boa ideia comparar medidas alternativas para cada objetivo.&lt;/p&gt;

&lt;p&gt;Por fim, uma questão interessante que se coloca é: &lt;strong&gt;não é possível ter uma única medida capaz de sumarizar tanto a acurácia como o risco em um modelo de previsão?&lt;/strong&gt; A resposta parece ser positiva. No artigo &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0169207018301547&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Tales from tails: On the empirical distributions of forecasting errors and their implication to risk&lt;/em&gt;&lt;/a&gt;, os autores propõem uma medida chamada Risk measure (RM). A ideia é relativamente simples: aplica-se uma transformação do tipo Box-Cox sobre a distribuição dos erros de previsão a fim de normalizá-los e em seguida calcula-se a medida que é a soma da média com o desvio-padrão da distribuição transformada. Ao fim, a transformação é revertida. A tabela abaixo computa uma versão da medida RM para os erros de previsão dos modelos (transformados via Box-Cox) em conjunto com o p-valor associado ao teste Shapiro de normalidade.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;modelo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;MAE&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SD&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;RM&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;shapiro_bc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;dotm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.94&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ces&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.26&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.79&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.93&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;arima&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.09&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.06&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ets&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13.48&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;O problema é que nem sempre a distribuição transformada é normal. O modelo DOTM apresentou a menor RM, porém os resultados não são significativos uma vez que somente a distribuição dos erros do modelo CES &amp;ndash; e com alguma &amp;ldquo;boa vontade&amp;rdquo; a do ARIMA &amp;ndash; se aproximou de uma distribuição normal. &lt;strong&gt;De fato, em termos de p-valor, a distribuição original dos erros apresentou resultados melhores para o teste de normalidade: respectivamente 0.14, 0.15, 0.11 e 0.02.&lt;/strong&gt; Ainda assim, o ideal seria ter p-valores maiores para dar mais segurança.&lt;/p&gt;

&lt;p&gt;Os códigos dos exercícios encontram-se disponíveis no &lt;a href=&#34;https://github.com/leripio/blog&#34; target=&#34;_blank&#34;&gt;repositório do blog no github.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Combinando modelos de previsão</title>
      <link>/post/combinando-modelos-de-previsao/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/combinando-modelos-de-previsao/</guid>
      <description>&lt;p&gt;Em posts anteriores apresentei algumas metodologias capazes de melhorar previsões. Em particular, falei um pouco sobre &lt;strong&gt;bagging&lt;/strong&gt; — uma técnica que estima um modelo específico sobre variações da série original e, em seguida, computa a média/mediana destas previsões &lt;a href=&#34;http://rleripio.com.br/post/como-aprimorar-previsoes-uma-aplicacao-com-bootstrap/&#34;&gt;(ver aqui)&lt;/a&gt; — e sobre &lt;strong&gt;rectify&lt;/strong&gt; — uma abordagem que considera eventuais informações contidas nos erros de previsão &lt;a href=&#34;http://rleripio.com.br/post/melhorando-previsoes-a-partir-dos-erros-a-estrategia-rectify/&#34;&gt;(ver aqui)&lt;/a&gt;. Em todos os casos considerei apenas um único modelo para realizar as previsões. Porém, com frequência temos à disposição mais de um modelo para a mesma variável. Neste caso, o que fazer?&lt;/p&gt;

&lt;p&gt;Uma estratégia muito comum consiste em combinar previsões de diversos modelos. Isso não é novidade e vem sendo explorado desde o paper seminal de Bates e Granger em 1969, &lt;em&gt;“The combination of forecasts“&lt;/em&gt;, com resultados bastante promissores. Entretanto, a estratégia parece ter definido um novo padrão no campo de previsões uma vez que &lt;strong&gt;12 dos 17 modelos mais acurados na competição M4 foram combinações&lt;/strong&gt;. Isto se deve, em grande medida, ao menor risco de repousar exclusivamente em um modelo mal especificado ou com baixa capacidade de adaptação a novos eventos.&lt;/p&gt;

&lt;p&gt;Existem diversas estratégias para combinar previsões. As abordagens mais comuns utilizam alguma medida como média simples/mediana ou fazem uso de alguma combinação linear das previsões, conforme a expressão abaixo:&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ y^{FC}_{t} = \alpha_1 y_{1,t}^{FC} + \alpha_2 y_{2,t}^{FC} + ... + \alpha_k y_{k,t}^{FC} = \sum_i^k \alpha_i y_{i,t}^{FC} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;em que $y_{i,t}^{FC}$ é a previsão do modelo $i$ para o período $t$.&lt;/p&gt;

&lt;p&gt;Os pesos, $\alpha_i$, podem ser definidos de diversas formas. Em geral, considera-se alguma medida do erro de previsão de cada modelo, dando menor peso ao modelo que historicamente errou mais; ou então obtém-se os pesos através da minimização de alguma função perda (RMSFE, MSFE, etc). Métodos mais sofisticados permitem, por exemplo, mudanças no valor dos parâmetros ao longo do tempo e até mesmo a utilização de algoritmos de Machine Learning para aprender o valor destes parâmetros.&lt;/p&gt;

&lt;p&gt;Neste post, vou considerar quatro modelos univariados: &lt;strong&gt;ETS&lt;/strong&gt;, &lt;strong&gt;CES&lt;/strong&gt; (complex exponential smoothing), &lt;strong&gt;ARIMA&lt;/strong&gt; e &lt;strong&gt;DOTM&lt;/strong&gt; (dynamic optimised theta). A primeira abordagem para combinação será computar a mediana das projeções individuais. A escolha conjunta destes modelos e da mediana para combinação não é arbitrária, mas segue a proposta de &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0169207019300585&#34;&gt;Petropoulos e Svetunkov (2019, IJF)&lt;/a&gt;, a qual, embora simples, obteve excelentes resultados. A segunda abordagem para combinação considera os mesmos modelos e pesos $\alpha_i$ que minimizam o RMSFE (root mean squared forecast error), de acordo com:&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ min_{\alpha_i} \frac{\sum_{t = 1}^{T} ( y_t - \sum_i^{k} \alpha_i y_{i,t}^{FC} )^2}{n} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Os leitores mais familiarizados vão notar que este problema pode ser reduzido à uma regressão linear entre o y observado em $t$ e as projeções de cada um dos modelos para o mesmo $t$. Em especial, ao elevar ao quadrado os resíduos da regressão, calcular a média e extrair a raiz, obteremos o RMSFE. Entretanto, para deixar o tratamento mais geral, vou considerar o problema de otimização acima. Adicionalmente, para que os coeficientes $\alpha_i$ sejam não-negativos e somem um, vou aplicar uma transformação sobre eles utilizando a função &lt;strong&gt;softmax&lt;/strong&gt;. O objetivo é deixar mais intuitiva a noção de pesos. Portanto, os coeficientes $\alpha_i$ padronizados serão dados por:&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \bar{\alpha_i} = \frac{e^{\alpha_i}}{\sum_i^k e^{\alpha_i}} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Por fim, vamos comparar os resultados dos modelos individuais com aqueles obtidos através das combinações. Antes de começarmos, é preciso chamar atenção para três pontos. Em primeiro lugar, como quase tudo em forecasting, as evidências que apontam vantagem de previsões combinadas sobre as individuais são obtidas ao aplicar o método sobre um grande conjunto de séries. Ou seja, a superioridade dos métodos de combinação vale na média e não necessariamente para todos os casos particulares.&lt;/p&gt;

&lt;p&gt;Em segundo lugar, a combinação de modelos pressupõe que os modelos gerem previsões não-viesadas. Caso contrário, o viés de um dos modelos acaba contaminando a previsão combinada. Por esta razão, incluir uma constante no problema de otimização pode melhorar o resultado, uma vez que captura algum eventual viés.&lt;/p&gt;

&lt;p&gt;Por último, é preciso ter cuidado ao avaliar o poder preditivo dos modelos. No caso da combinação linear, como precisamos gerar previsões para calcular o valor dos pesos $\alpha_i$, vamos separar uma parte da amostra para validação. Para ficar mais claro, faremos o seguinte:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A amostra de treino será utilizada para computar as projeções de cada método;&lt;/li&gt;
&lt;li&gt;O peso de cada método será computado tendo como referência o poder preditivo sobre a amostra de validação;&lt;/li&gt;
&lt;li&gt;Os pesos obtidos na etapa 2 serão utilizados para combinar as projeções obtidas na amostra de treino ampliada (treino+validação).&lt;/li&gt;
&lt;li&gt;Estas projeções da etapa 3 serão comparadas com os valores da amostra de teste.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Entendido o exercício, abra o R e acompanhe!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Passo 1: carregar os pacotes necessários, importar os dados e definir as amostras.&lt;/strong&gt; Para esta aplicação, vamos utilizar a série do núcleo do IPCA EX-3, calculado pelo BCB (SGS 27839).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# 1. Carregar bibliotecas

library(tidyverse)
library(rbcb) # Para instalar: devtools::install_github(&amp;quot;wilsonfreitas/rbcb&amp;quot;)
library(forecast) 
library(smooth) 
library(forecTheta) 
library(knitr)

# 2. Importar dados dados

dados &amp;lt;- rbcb::get_series(list(&amp;quot;ipca_ex3&amp;quot; = 27839), 
                          start_date = &amp;quot;2006-07-01&amp;quot;, 
                          end_date = &amp;quot;2019-05-01&amp;quot;) 
dados_ts &amp;lt;- ts(dados$ipca_ex3, start = c(2006,7), freq = 12) 

# 3. Separar as amostras (cerca de 55% para treino, 30% para validação e 15% para teste) 

dados_treino &amp;lt;- window(dados_ts, end = c(2013,7)) 
dados_valida &amp;lt;- window(dados_ts, start = c(2013,8), end = c(2017,5)) 
dados_teste &amp;lt;- window(dados_ts, start = c(2017,6)) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: realizar as projeções individuais para cada modelo com horizonte igual ao período de validação.&lt;/strong&gt; Estes dados serão utilizados para estimar os pesos.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;modelo_i &amp;lt;- list(

  &amp;quot;ets&amp;quot; = function(x,h) forecast(ets(x, lambda = &amp;quot;auto&amp;quot;), h = h),
  &amp;quot;ces&amp;quot; = function(x,h) forecast(smooth::auto.ces(x), h = h),
  &amp;quot;arima&amp;quot; = function(x,h) forecast(auto.arima(x), h = h),
  &amp;quot;dotm&amp;quot; = function(x,h) forecTheta::dotm(x, h = h)
)

fc_i &amp;lt;- purrr::invoke_map(.f = modelo_i, 
                          .x = list(dados_treino), 
                          h = length(dados_valida))

fc_i_mean &amp;lt;- purrr::map_dfc(.x = fc_i, .f = function(x) x[[&amp;quot;mean&amp;quot;]]) %&amp;gt;% 
             dplyr::mutate(y_valida = dados_valida)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: computar os parâmetros que minimizam a RMSFE e normalizá-los.&lt;/strong&gt; Aqui, como eram apenas 4 modelos eu abri o somatório para ficar mais claro. Para o caso de um conjunto grande de modelos, o ideal é substituir por uma operação matricial.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;msfe_comb &amp;lt;- function(x){

  alpha_ets &amp;lt;- x[1]
  alpha_ces &amp;lt;- x[2]
  alpha_arima &amp;lt;- x[3]
  alpha_dotm &amp;lt;- x[4]

  ((fc_i_mean$y_valida - alpha_ets*fc_i_mean$ets - alpha_ces*fc_i_mean$ces - 
    alpha_arima*fc_i_mean$arima - alpha_dotm*fc_i_mean$dotm)^2) %&amp;gt;% 
  
  mean() %&amp;gt;% 
  
  sqrt()

  }

pesos &amp;lt;- optim(c(1,1,1,1), msfe_comb)

pesos_norm &amp;lt;- round(exp(pesos$par)/sum(exp(pesos$par)), 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 4: realizar as projeções combinadas utilizando os parâmetros estimados e a mediana&lt;/strong&gt;. Em seguida, comparar com as realizações da amostra de teste.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dados_treino_amplo &amp;lt;- window(dados_ts, end = c(2017,5))

fc_i_amplo &amp;lt;- purrr::invoke_map(.f = modelo_i, 
                                .x = list(dados_treino_amplo), 
                                h = length(dados_teste))
fc_i_mean_amplo &amp;lt;- purrr::map_dfc(.x = fc_i_amplo, 
                                  .f = function(x) x[[&amp;quot;mean&amp;quot;]]) %&amp;gt;%

  dplyr::mutate(&amp;quot;y_teste&amp;quot; = dados_teste) %&amp;gt;%

  dplyr::rowwise() %&amp;gt;%

  dplyr::mutate(&amp;quot;Mediana&amp;quot; = median(c(ets,ces,arima,dotm))) %&amp;gt;%

  dplyr::ungroup() %&amp;gt;%

  dplyr::mutate(&amp;quot;Otimização&amp;quot; = pesos_norm[1]*ets + pesos_norm[2]*ces + 
                             pesos_norm[3]*arima + pesos_norm[4]*dotm)

fc_i_acc &amp;lt;- fc_i_mean_amplo %&amp;gt;% 
  
  dplyr::summarise_at(vars(-y_teste), 
                      funs(forecast::accuracy(., y_teste)[, &amp;quot;RMSE&amp;quot;]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As medidas de acurácia são exibidas na tabela abaixo. A estratégia de combinação através da mediana apresentou o melhor resultado, superando ligeiramente os modelos CES e ETS. A combinação através de otimização, por sua vez, não foi capaz de bater todos os modelos individuais. Mais especificamente, o bom desempenho do modelo arima no período de validação fez com que este recebesse um peso mais elevado. Entretanto, essa vantagem não se materializou no período de teste. Isto reforça a necessidade de reavaliar modelos e estratégias de tempos em tempos, sobretudo quando ocorrem mudanças estruturais na série de interesse -- como foi o caso do IPCA EX-3. Por outro lado, também reforça a capacidade de estratégias que utilizam medidas de tendência menos sensíveis a extremos -- como a mediana -- em responder melhor a ambientes mais incertos.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Modelo&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;RMSFE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Mediana&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.121&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ces&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.123&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ets&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.123&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;dotm&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.131&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Otimização&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.143&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;arima&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.184&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;O gráfico abaixo apresenta as observações para o IPCA EX-3 da amostra de teste e as previsões pontuais geradas pelos dois métodos de combinação. Vale ressaltar que uma análise mais rigorosa levaria em conta também a performance para cada horizonte. Também fica claro ao observar o gráfico que os picos e vales mais pronunciados podem ter um papel relevante sobre a magnitude da medida RMSFE. Uma boa prática seria considerar medidas alternativas, sobretudo aquelas mais robustas a este tipo de situação. Pretendo abordar isso em algum momento.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;2019-07-11-combinando-modelos-de-previsão_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;3600&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Por fim, cabe notar que intervalo de confiança nesses casos não é trivial, uma vez que é preciso obter uma expressão para a variância da combinação das previsões, o que requer computar as covariâncias entre os erros dos modelos. Uma solução conservadora é utilizar o intervalo mais amplo dos modelos individuais, porém não me agrada muito. Talvez possamos voltar nesse ponto em uma próxima oportunidade.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sugestão&lt;/strong&gt;: Para os interessados em aplicar metodologias de combinação de previsões, existem alguns pacotes disponíveis para R. Dois deles (opera e ForecastHybrid) são tratados neste post do Rob. Hyndman: &lt;a href=&#34;https://robjhyndman.com/hyndsight/forecast-combinations/&#34;&gt;https://robjhyndman.com/hyndsight/forecast-combinations/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Os códigos dos exercícios encontram-se disponíveis no &lt;a href=&#34;http://github.com/leripio/blog&#34;&gt;repositório&lt;/a&gt; do blog no github.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Como aprimorar previsões: uma aplicação com bootstrap</title>
      <link>/post/como-aprimorar-previsoes-uma-aplicacao-com-bootstrap/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      <guid>/post/como-aprimorar-previsoes-uma-aplicacao-com-bootstrap/</guid>
      <description>&lt;p&gt;O exercício de hoje tem como objetivo apresentar uma técnica com potencial para aprimorar a previsão pontual de uma série, conhecida como &lt;strong&gt;bagging&lt;/strong&gt; (&lt;em&gt;bootstrap aggregating&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Partindo do pressuposto de que toda série temporal é uma realização específica de um processo estocástico, o que este método faz é gerar outras possíveis realizações (séries) deste mesmo processo gerador. E como isso é feito?&lt;/p&gt;

&lt;p&gt;Em primeiro lugar, a série original é decomposta em tendência, sazonalidade e restante (pense neste último termo como a parte aleatória da série). Este termo restante é submetido a um processo de bootstrap, isto é, ele sofre um processo de re-amostragem. Todavia, como o termo aleatório de uma série temporal pode ser correlacionado no tempo, esta re-amostragem não é feita por observações, mas em blocos — &lt;strong&gt;blocked bootstrap&lt;/strong&gt;. Por fim, estes novos componentes aleatórios obtidos via bootstrap são reintroduzidos aos componentes de tendência e sazonalidade da série original formando novas séries que são variantes dela.&lt;/p&gt;

&lt;p&gt;Para ficar mais claro, considere o gráfico abaixo. A linha preta é a série original da taxa de desocupação medida pela Pnad Contínua Mensal (IBGE). As linhas coloridas são séries calculadas a partir do processo descrito acima. Do ponto de vista estatístico, qualquer uma daquelas séries poderia ter ocorrido, sendo a série “verdadeira” aquela que efetivamente ocorreu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;2018-09-13-como-aprimorar-previsões-uma-aplicação-com-bootstrap_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, entendido até aqui. E agora? Agora, o método consiste em obter as previsões para cada uma das séries e calcular a média das previsões. Você pode estar se perguntando se, de fato, este método melhora o poder preditivo de um modelo. Existem trabalhos que mostram aumento de performance, na média, para alguns modelos. De todo modo, é aconselhável checar se o mesmo é válido para a série e para o modelo que estamos utilizando. Vamos fazer um exemplo?&lt;/p&gt;

&lt;p&gt;Antes de começarmos, uma breve explicação. Utilizaremos a função bld.mbb.bootstrap() do pacote forecast para calcular as séries via bootstrap, conforme o gráfico acima. O resultado será um objeto do tipo lista com as séries geradas. Em seguida, vamos utilizar a função map() do pacote purrr para gerar previsões para cada uma das séries através do auto.arima(), também do pacote forecast. Mas lembre-se que você pode utilizar qualquer modelo que desejar. O pacote forecast tem uma implementação direta através da função baggedModel(), mas eu preferi desagregar o trabalho para deixar mais claro como é feito. Por fim, vamos comparar os erros de previsão (fora da amostra) da série original e da média das séries geradas (bagging).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Passo 1: carregar pacotes necessários&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(sidrar)
library(tidyverse)
library(forecast)
library(timetk)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 2: importar a série temporal da PNAD&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pnad &amp;lt;- sidrar::get_sidra(api = &amp;quot;/t/6381/n1/all/v/4099/p/all/d/v4099%201&amp;quot;)

pnad_ts &amp;lt;- ts(pnad$Valor, start = c(2012,3), freq = 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 3: definir amostras de treino e de teste para medir a acurácia das previsões e também o número de séries geradas por bootstrap&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pnad_treino &amp;lt;- window(pnad_ts, end = c(2016,7))

pnad_teste &amp;lt;- window(pnad_ts, start = c(2016,8))

k &amp;lt;- 10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 4: computar as séries via bootstrap&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pnad_boot &amp;lt;- forecast::bld.mbb.bootstrap(pnad_treino, k) %&amp;gt;%
  
  purrr::map(.f = ts, start = c(2012,3), freq = 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 5: computar previsões por auto.arima, por bagging&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;aa_fc &amp;lt;- function(x){forecast(auto.arima(x, max.d = 1), n = 24)[[&amp;quot;mean&amp;quot;]]}

pnad_boot_fc &amp;lt;- purrr::map(.x = pnad_boot, .f = aa_fc)

## Computar a previsão pelo método bagging

fc_original &amp;lt;- pnad_boot_fc[[1]]

fc_bagged &amp;lt;- pnad_boot_fc %&amp;gt;% purrr::reduce(`+`) %&amp;gt;% `/`(k)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Passo 6: comparar a acurácia dos modelos&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;accuracy(fc_original, pnad_teste)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                 ME     RMSE      MAE       MPE    MAPE      ACF1 Theil&#39;s U
## Test set -2.362092 3.129262 2.363582 -18.89847 18.9103 0.8906952   10.3499
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;accuracy(fc_bagged, pnad_teste)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                 ME     RMSE      MAE       MPE     MAPE      ACF1
## Test set -1.947639 2.682957 2.013009 -15.56498 16.10364 0.8898631
##          Theil&#39;s U
## Test set   8.86905
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;De fato, como é possível observar, as previsões a partir do método &lt;strong&gt;bagging&lt;/strong&gt; apresentaram desempenho superior.&lt;/p&gt;

&lt;p&gt;Os códigos dos exercícios encontram-se disponíveis no &lt;a href=&#34;http://github.com/leripio/blog&#34; target=&#34;_blank&#34;&gt;repositório&lt;/a&gt; do blog no github.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aviso legal&lt;/strong&gt;: Todo o conteúdo desta página é de responsabilidade pessoal do autor e não expressa a visão da instituição a qual o autor tem vínculo profissional.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
